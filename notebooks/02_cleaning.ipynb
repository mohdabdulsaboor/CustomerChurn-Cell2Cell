{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "022d609c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_cols: 35 | cat_cols: 22\n",
      "Saved artifacts/columns.json\n",
      "Saved artifacts/preprocessor.joblib\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# # 02 â€” Cleaning & Preprocessing (Improved)\n",
    "# Goals:\n",
    "# - Identify numeric/categorical columns\n",
    "# - Rare-category bucketing (replace infrequent levels with \"Other\")\n",
    "# - Build reusable preprocessing pipeline (impute + OHE)\n",
    "# - Save metadata (columns) and preprocessor artifact\n",
    "\n",
    "# %%\n",
    "import os, json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder  # encoder only saved inside ColumnTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# ---- Set your project root (edit if your path differs)\n",
    "os.chdir(r\"C:\\Users\\dell\\Desktop\\Cell2Cell_Project\")\n",
    "\n",
    "DATA_RAW = Path('data/raw')\n",
    "ART = Path('artifacts'); ART.mkdir(exist_ok=True)\n",
    "\n",
    "train = pd.read_csv(DATA_RAW / 'cell2celltrain.csv')\n",
    "assert 'Churn' in train.columns, \"Churn column missing\"\n",
    "\n",
    "y = (train['Churn'] == 'Yes').astype(int)\n",
    "X = train.drop(columns=['Churn'])\n",
    "\n",
    "# %%\n",
    "# Identify numeric vs categorical\n",
    "num_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_cols = [c for c in X.columns if c not in num_cols]\n",
    "print('num_cols:', len(num_cols), '| cat_cols:', len(cat_cols))\n",
    "\n",
    "# %%\n",
    "# Rare-category bucketing for categorical columns (frequency <1% -> \"Other\")\n",
    "def bucket_rare_categories(df, cols, min_frac=0.01):\n",
    "    df = df.copy()\n",
    "    n = len(df)\n",
    "    for c in cols:\n",
    "        vc = df[c].value_counts(dropna=False)\n",
    "        rare_levels = vc[vc < n * min_frac].index\n",
    "        df[c] = df[c].where(~df[c].isin(rare_levels), 'Other')\n",
    "    return df\n",
    "\n",
    "X_bucketed = bucket_rare_categories(X, cat_cols, min_frac=0.01)\n",
    "\n",
    "# %%\n",
    "# Build preprocessing pipeline:\n",
    "# - Numerics: impute median\n",
    "# - Categoricals: impute most_frequent + OHE (sparse_output=True for speed)\n",
    "from sklearn.preprocessing import StandardScaler  # (optional, not used by trees)\n",
    "\n",
    "num_pipe = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    # ('scaler', StandardScaler())  # uncomment if you add linear models later\n",
    "])\n",
    "\n",
    "cat_pipe = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('ohe', OneHotEncoder(handle_unknown='ignore', sparse_output=True))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', num_pipe, num_cols),\n",
    "    ('cat', cat_pipe, cat_cols)\n",
    "])\n",
    "\n",
    "# Fit preprocessor once (learn categories, etc.)\n",
    "preprocessor.fit(X_bucketed)\n",
    "\n",
    "# Save metadata\n",
    "with open(ART / 'columns.json','w') as f:\n",
    "    json.dump({'num_cols': num_cols, 'cat_cols': cat_cols}, f)\n",
    "print('Saved artifacts/columns.json')\n",
    "\n",
    "# Save the preprocessor\n",
    "import joblib\n",
    "joblib.dump(preprocessor, ART / 'preprocessor.joblib')\n",
    "print('Saved artifacts/preprocessor.joblib')\n"
     "print(preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48ce237-1f4a-4bd2-8651-d1474ccd5e7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
