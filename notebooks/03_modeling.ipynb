{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d11bef59",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation metrics @0.50:\n",
      "                model  accuracy  precision    recall       f1   roc_auc\n",
      "0  RandomForest_fast  0.688149   0.441827  0.312373  0.36599  0.658235\n",
      "Saved: validation_metrics.csv, best_model.joblib, confusion_matrix_default.png, roc_curve.png, pr_curve.png\n",
      "Saved thresholds: f1=0.379, top20≈0.501\n",
      "Saved: data/cleaned/validation_scored_with_deciles.csv, data/cleaned/holdout_scored.csv, artifacts/thresholds.json\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# # 03 — Modeling (Fast Version — No CV)\n",
    "# Random Forest with sensible defaults (balanced class weights), ROC/PR, threshold tuning,\n",
    "# and BI-ready scored outputs. No hyper-parameter search to avoid long runs.\n",
    "\n",
    "# %%\n",
    "import os, json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score,\n",
    "    roc_curve, precision_recall_curve, ConfusionMatrixDisplay\n",
    ")\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import joblib\n",
    "\n",
    "# ---- Set your project root (edit if different)\n",
    "os.chdir(r\"C:\\Users\\dell\\Desktop\\Cell2Cell_Project\")\n",
    "\n",
    "DATA_RAW = Path('data/raw')\n",
    "CLEANED = Path('data/cleaned'); CLEANED.mkdir(parents=True, exist_ok=True)\n",
    "ART = Path('artifacts'); ART.mkdir(parents=True, exist_ok=True)\n",
    "IMG = Path('report/images'); IMG.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ---- Load data\n",
    "train = pd.read_csv(DATA_RAW / 'cell2celltrain.csv')\n",
    "y = (train['Churn'] == 'Yes').astype(int)\n",
    "X = train.drop(columns=['Churn'])\n",
    "\n",
    "# Load columns + preprocessor from 02_cleaning\n",
    "meta = json.load(open(ART / 'columns.json'))\n",
    "num_cols, cat_cols = meta['num_cols'], meta['cat_cols']\n",
    "pre = joblib.load(ART / 'preprocessor.joblib')\n",
    "\n",
    "# Rare-category bucketing (same as 02) to keep categories consistent\n",
    "def bucket_rare_categories(df, cols, min_frac=0.01):\n",
    "    df = df.copy()\n",
    "    n = len(df)\n",
    "    for c in cols:\n",
    "        vc = df[c].value_counts(dropna=False)\n",
    "        rare_levels = vc[vc < n * min_frac].index\n",
    "        df[c] = df[c].where(~df[c].isin(rare_levels), 'Other')\n",
    "    return df\n",
    "\n",
    "X = bucket_rare_categories(X, cat_cols, min_frac=0.01)\n",
    "\n",
    "# ---- Split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# ---- Fast, sensible Random Forest (no CV)\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=18,                 # cap depth to reduce overfit + speed up\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2,\n",
    "    max_features='sqrt',\n",
    "    class_weight='balanced_subsample',  # help class imbalance\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "pipe = Pipeline([('pre', pre), ('clf', rf)])\n",
    "\n",
    "# ---- Train\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# ---- Evaluate (default 0.50 threshold)\n",
    "pred = pipe.predict(X_valid)\n",
    "proba = pipe.predict_proba(X_valid)[:, 1]\n",
    "metrics = {\n",
    "    'model': 'RandomForest_fast',\n",
    "    'accuracy': accuracy_score(y_valid, pred),\n",
    "    'precision': precision_score(y_valid, pred),\n",
    "    'recall': recall_score(y_valid, pred),\n",
    "    'f1': f1_score(y_valid, pred),\n",
    "    'roc_auc': roc_auc_score(y_valid, proba)\n",
    "}\n",
    "print(\"Validation metrics @0.50:\\n\", pd.DataFrame([metrics]))\n",
    "\n",
    "# Save metrics + model\n",
    "pd.DataFrame([metrics]).to_csv(ART / 'validation_metrics.csv', index=False)\n",
    "joblib.dump(pipe, ART / 'best_model.joblib')\n",
    "\n",
    "# Confusion matrix (0.50)\n",
    "ConfusionMatrixDisplay.from_predictions(y_valid, pred)\n",
    "plt.title('Confusion Matrix (thr=0.50)')\n",
    "plt.tight_layout()\n",
    "plt.savefig(IMG / 'confusion_matrix_default.png', dpi=150)\n",
    "plt.close()\n",
    "\n",
    "# ROC curve\n",
    "fpr, tpr, _ = roc_curve(y_valid, proba)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr); plt.plot([0,1],[0,1],'--')\n",
    "plt.xlabel('FPR'); plt.ylabel('TPR'); plt.title('ROC Curve')\n",
    "plt.tight_layout(); plt.savefig(IMG / 'roc_curve.png', dpi=150); plt.close()\n",
    "\n",
    "# PR curve\n",
    "prec, rec, pr_thr = precision_recall_curve(y_valid, proba)\n",
    "plt.figure()\n",
    "plt.plot(rec, prec)\n",
    "plt.xlabel('Recall'); plt.ylabel('Precision'); plt.title('Precision-Recall Curve')\n",
    "plt.tight_layout(); plt.savefig(IMG / 'pr_curve.png', dpi=150); plt.close()\n",
    "print(\"Saved: validation_metrics.csv, best_model.joblib, confusion_matrix_default.png, roc_curve.png, pr_curve.png\")\n",
    "\n",
    "# ---- Threshold tuning\n",
    "# (A) F1-optimal threshold\n",
    "f1_scores = 2 * (prec * rec) / (prec + rec + 1e-12)\n",
    "best_idx = np.nanargmax(f1_scores)\n",
    "best_thr_f1 = pr_thr[best_idx] if best_idx < len(pr_thr) else 0.5\n",
    "pred_f1 = (proba >= best_thr_f1).astype(int)\n",
    "\n",
    "ConfusionMatrixDisplay.from_predictions(y_valid, pred_f1)\n",
    "plt.title(f'Confusion Matrix (F1-optimal thr={best_thr_f1:.2f})')\n",
    "plt.tight_layout(); plt.savefig(IMG / 'confusion_matrix_f1.png', dpi=150); plt.close()\n",
    "\n",
    "# (B) Business threshold: top 20% highest risk\n",
    "thr_top20 = float(np.quantile(proba, 0.80))\n",
    "pred_top20 = (proba >= thr_top20).astype(int)\n",
    "\n",
    "ConfusionMatrixDisplay.from_predictions(y_valid, pred_top20)\n",
    "plt.title(f'Confusion Matrix (top-20% thr≈{thr_top20:.2f})')\n",
    "plt.tight_layout(); plt.savefig(IMG / 'confusion_matrix_top20.png', dpi=150); plt.close()\n",
    "\n",
    "with open(ART / 'thresholds.json','w') as f:\n",
    "    json.dump({'f1_optimal': float(best_thr_f1), 'top20': float(thr_top20)}, f)\n",
    "\n",
    "print(f\"Saved thresholds: f1={best_thr_f1:.3f}, top20≈{thr_top20:.3f}\")\n",
    "\n",
    "# ---- BI-friendly scored outputs\n",
    "valid_scores = pd.DataFrame({'proba': proba, 'actual': y_valid.reset_index(drop=True)})\n",
    "valid_scores['decile'] = pd.qcut(valid_scores['proba'], 10, labels=False, duplicates='drop')\n",
    "valid_scores.to_csv(CLEANED / 'validation_scored_with_deciles.csv', index=False)\n",
    "\n",
    "# Score HOLDOUT with same preprocessing + rare-bucket\n",
    "holdout = pd.read_csv(DATA_RAW / 'cell2cellholdout.csv')\n",
    "holdout = bucket_rare_categories(holdout, cat_cols, min_frac=0.01)\n",
    "holdout_proba = pipe.predict_proba(holdout)[:, 1]\n",
    "out = holdout.copy()\n",
    "out['churn_probability'] = holdout_proba\n",
    "out['decile'] = pd.qcut(out['churn_probability'], 10, labels=False, duplicates='drop')\n",
    "out.to_csv(CLEANED / 'holdout_scored.csv', index=False)\n",
    "\n",
    "print(\"Saved: data/cleaned/validation_scored_with_deciles.csv, data/cleaned/holdout_scored.csv, artifacts/thresholds.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d5b6a4-d310-4fae-8d24-e74040c00d9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
